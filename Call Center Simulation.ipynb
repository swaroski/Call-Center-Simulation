{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simpy\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Define a set of globals that define the characteristics of the model instance to be simulated. This includes the seed (RANDOM_SEED) for the random number generators, and key parameters for the interarrival (i.e. mean arrival rate) and service time (i.e. mean and std for lognormal and exponential) distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RANDOM_SEED = 978\n",
    "\n",
    "CUSTOMER_COUNT = 1000\n",
    "\n",
    "INTERARRIVAL_MEAN = 14.3\n",
    "INTERARRIVAL_RATE = 1.0 / INTERARRIVAL_MEAN\n",
    "\n",
    "m = 7.2\n",
    "v = 2.7\n",
    "phi = math.sqrt(v + m ** 2)\n",
    "SERVICE_FRONTDESK_MEAN = math.log(m ** 2 / phi)\n",
    "SERVICE_FRONTDESK_STD = math.sqrt(math.log(phi ** 2 / m ** 2))\n",
    "\n",
    "SERVICE_EXPERT_MEAN = 10.2\n",
    "SERVICE_EXPERT_RATE = 1.0 / SERVICE_EXPERT_MEAN\n",
    "\n",
    "RENEGING_MEAN = 60.0\n",
    "RENEGING_RATE = 1.0 / RENEGING_MEAN\n",
    "\n",
    "BREAK_MEAN = 60.0\n",
    "BREAK_RATE = 1.0 / BREAK_MEAN\n",
    "\n",
    "BREAK_TIME = 3\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The class definition for the customers arriving at the modeled system. When they are created, they immediatelly initiate a call (i.e. activate the call process).\n",
    "\n",
    "- Once a call is initiated, this is registered as a request to the frontdesk operator resource. The customer is put on hold until the frontdesk resource activates it back.\n",
    "\n",
    "- When the frontdesk resource is available, the customer is activated and it then initiates the serve_frontdesk process. The duration of a serve_frontdesk session is determined randomly according to a LogNormal distribution.\n",
    "\n",
    "- Then, a request to the expert operator resource is registered for the same call. The customer is put on hold until the expert resource activates it back.\n",
    "\n",
    "- When the expert resource is available, the customer is activated and it then initiates the serve_expert process. The duration of a serve_expert session is determined randomly according to an exponantial distribution.\n",
    "\n",
    "- Customers in the expert resource's queue leave the system without getting service when they wait for a random time according to an exponantial distribution.\n",
    "\n",
    "- Expert resource stops operating for 3 minutes at random times accoring to a Poisson distribution. When it decides to stop, it serves all customers in it's queue before stopping. New calls made when the expert resource stops is put on hold until the resource starts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Customer(object):\n",
    "    def __init__(self, name, env, frontdesk, expert):\n",
    "        self.name = name\n",
    "        self.env = env\n",
    "        self.frontdesk = frontdesk\n",
    "        self.expert = expert\n",
    "        self.arrival = self.env.now\n",
    "        self.action = env.process(self.call())\n",
    "    \n",
    "    def call(self):\n",
    "        #print('%s initiated a call at %g' % (self.name, self.env.now))\n",
    " \n",
    "        # a call is initiated and registered as a request to the frontdesk operator\n",
    "        with self.frontdesk.request() as req:\n",
    "            yield req\n",
    "            #print('%s is assigned to the frontdesk at %g' % (self.name, self.env.now))\n",
    "            # add the waiting time of that customer to waiting_times\n",
    "            self.waiting_time_frontdesk = self.env.now - self.arrival\n",
    "            # call is served\n",
    "            yield self.env.process(self.serve_frontdesk())\n",
    "            #print('%s is done with the frontdesk at %g' % (self.name, self.env.now))\n",
    "            self.frontdesk_exited = self.env.now\n",
    "        \n",
    "        # call is registered as a request to the expert operator\n",
    "        with self.expert.request() as req:\n",
    "            reneg_time = random.expovariate(RENEGING_RATE)\n",
    "            # wait for expert or leave the system\n",
    "            results = yield req | self.env.timeout(reneg_time)\n",
    "            # customer waited less than reneg_time\n",
    "            if req in results:\n",
    "                #print('%s is assigned to the expert at %g' % (self.name, self.env.now))\n",
    "                # add the waiting time of that customer to waiting_times\n",
    "                self.waiting_time_expert = self.env.now - self.frontdesk_exited\n",
    "                # call is served\n",
    "                yield self.env.process(self.serve_expert())\n",
    "                #print('%s is done with the expert at %g' % (self.name, self.env.now))\n",
    "            else:\n",
    "                # customer reneged\n",
    "                #print('%s is reneged at %g' % (self.name, self.env.now))\n",
    "                self.waiting_time_expert = reneg_time\n",
    "                self.service_time_expert = 0\n",
    "            \n",
    "        customers.append(self)\n",
    "        # last customer sets end time\n",
    "        if len(customers) == CUSTOMER_COUNT:\n",
    "            global end_time\n",
    "            end_time = self.env.now\n",
    "            \n",
    "    def serve_frontdesk(self):\n",
    "        self.service_time_frontdesk = random.lognormvariate(SERVICE_FRONTDESK_MEAN, SERVICE_FRONTDESK_STD)\n",
    "        yield self.env.timeout(self.service_time_frontdesk)\n",
    "    \n",
    "    def serve_expert(self):\n",
    "        self.service_time_expert = random.expovariate(SERVICE_EXPERT_RATE)\n",
    "        yield self.env.timeout(self.service_time_expert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customer_generator(env, frontdesk, expert):\n",
    "    i = 1\n",
    "    # while end time has not been set by last customer yet\n",
    "    while end_time == 0:\n",
    "        yield env.timeout(random.expovariate(INTERARRIVAL_RATE))\n",
    "        Customer('Customer %s' % (i), env, frontdesk, expert)\n",
    "        i += 1\n",
    "\n",
    "def break_generator(env, expert):\n",
    "    # while end time has not been set by last customer yet\n",
    "    while end_time == 0:\n",
    "        yield env.timeout(random.expovariate(BREAK_RATE))\n",
    "        #print('Expert wants break at %g' % (env.now))\n",
    "        with expert.request() as req:\n",
    "            yield req\n",
    "            #print('Expert gives break at %g' % (env.now))\n",
    "            yield env.timeout(BREAK_TIME)\n",
    "            #print('Expert exits break at %g' % (env.now))\n",
    "            global break_counter\n",
    "            break_counter += BREAK_TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = []\n",
    "end_time = 0\n",
    "break_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilization of frontdesk: 0.510645\n",
      "Utilization of expert (including breaks): 0.624112\n",
      "Utilization of expert (excluding breaks): 0.650412\n",
      "Average Total Waiting Time: 11.1983\n",
      "Maximum Total Waiting Time to Total System Time Ratio: 0.917661\n",
      "Average number of people waiting to be served by expert: 0.523443\n"
     ]
    }
   ],
   "source": [
    "random.seed(RANDOM_SEED)\n",
    "env = simpy.Environment()\n",
    "frontdesk = simpy.Resource(env, capacity = 1)\n",
    "expert = simpy.Resource(env, capacity = 1)\n",
    "env.process(customer_generator(env, frontdesk, expert))\n",
    "env.process(break_generator(env, expert))\n",
    "env.run()\n",
    "total_service_time_frontdesk = 0\n",
    "total_service_time_expert = 0\n",
    "total_waiting_time_expert = 0\n",
    "total_waiting_time = 0\n",
    "max_ratio = 0\n",
    "for i in range(CUSTOMER_COUNT):\n",
    "    c = customers[i]\n",
    "    total_service_time_frontdesk += c.service_time_frontdesk\n",
    "    total_service_time_expert += c.service_time_expert\n",
    "    total_waiting_time_expert += c.waiting_time_expert\n",
    "    total_waiting_time += c.waiting_time_frontdesk + c.waiting_time_expert\n",
    "    max_ratio = max([max_ratio, ((c.waiting_time_frontdesk + c.waiting_time_expert) / (c.waiting_time_frontdesk + c.waiting_time_expert + c.service_time_frontdesk + c.service_time_expert))])\n",
    "print('Utilization of frontdesk: %g' % (total_service_time_frontdesk / end_time))\n",
    "print('Utilization of expert (including breaks): %g' % (total_service_time_expert / end_time))\n",
    "print('Utilization of expert (excluding breaks): %g' % (total_service_time_expert / (end_time - break_counter)))\n",
    "print('Average Total Waiting Time: %g' % (total_waiting_time / CUSTOMER_COUNT))\n",
    "print('Maximum Total Waiting Time to Total System Time Ratio: %g' % max_ratio)\n",
    "print('Average number of people waiting to be served by expert: %g' % (total_waiting_time_expert / end_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilization of frontdesk: 0.497092\n",
      "Utilization of expert (including breaks): 0.609585\n",
      "Utilization of expert (excluding breaks): 0.636116\n",
      "Average Total Waiting Time: 11.7349\n",
      "Maximum Total Waiting Time to Total System Time Ratio: 0.952532\n",
      "Average number of people waiting to be served by expert: 0.564514\n"
     ]
    }
   ],
   "source": [
    "CUSTOMER_COUNT = 5000\n",
    "customers = []\n",
    "end_time = 0\n",
    "break_counter = 0\n",
    "random.seed(RANDOM_SEED)\n",
    "env = simpy.Environment()\n",
    "frontdesk = simpy.Resource(env, capacity = 1)\n",
    "expert = simpy.Resource(env, capacity = 1)\n",
    "env.process(customer_generator(env, frontdesk, expert))\n",
    "env.process(break_generator(env, expert))\n",
    "env.run()\n",
    "total_service_time_frontdesk = 0\n",
    "total_service_time_expert = 0\n",
    "total_waiting_time_expert = 0\n",
    "total_waiting_time = 0\n",
    "max_ratio = 0\n",
    "for i in range(CUSTOMER_COUNT):\n",
    "    c = customers[i]\n",
    "    total_service_time_frontdesk += c.service_time_frontdesk\n",
    "    total_service_time_expert += c.service_time_expert\n",
    "    total_waiting_time_expert += c.waiting_time_expert\n",
    "    total_waiting_time += c.waiting_time_frontdesk + c.waiting_time_expert\n",
    "    max_ratio = max([max_ratio, ((c.waiting_time_frontdesk + c.waiting_time_expert) / (c.waiting_time_frontdesk + c.waiting_time_expert + c.service_time_frontdesk + c.service_time_expert))])\n",
    "print('Utilization of frontdesk: %g' % (total_service_time_frontdesk / end_time))\n",
    "print('Utilization of expert (including breaks): %g' % (total_service_time_expert / end_time))\n",
    "print('Utilization of expert (excluding breaks): %g' % (total_service_time_expert / (end_time - break_counter)))\n",
    "print('Average Total Waiting Time: %g' % (total_waiting_time / CUSTOMER_COUNT))\n",
    "print('Maximum Total Waiting Time to Total System Time Ratio: %g' % max_ratio)\n",
    "print('Average number of people waiting to be served by expert: %g' % (total_waiting_time_expert / end_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speechtest",
   "language": "python",
   "name": "speechtest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
